{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenpinghsuan/Documents/Kaggle/virenv/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary', 'total_payments', 'bonus', 'total_stock_value', 'exercised_stock_options',\n",
    "                 'long_term_incentive','from_poi_to_this_person', 'from_this_person_to_poi',\n",
    "                 'shared_receipt_with_poi','to_messages', 'from_messages']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 2: Remove outliers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dict.pop('TOTAL', 0) \n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0) # not a real person\n",
    "data_dict.pop('LOCKHART EUGENE E', 0) # all value missing for this person\n",
    "\n",
    "# convert to pandas dataframe\n",
    "data_dict_df = pd.DataFrame.from_dict(data_dict, orient='columns')\n",
    "\n",
    "# replacing 'NaN' string in dataframe\n",
    "for column in data_dict_df:\n",
    "    data_dict_df[column].replace('NaN',np.nan, inplace=True)\n",
    "    \n",
    "# only keeping columns that's in feature list\n",
    "sel_data = data_dict_df.loc[features_list]\n",
    "sel_data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "\n",
    "import copy\n",
    "\n",
    "data_dict = copy.deepcopy(sel_data)\n",
    "\n",
    "for key in data_dict:\n",
    "    if (data_dict[key]['to_messages'] != 'NaN' and \n",
    "        data_dict[key]['to_messages'] != 0 and \n",
    "        data_dict[key]['from_poi_to_this_person'] != 'NaN' and \n",
    "        data_dict[key]['from_poi_to_this_person'] != 0) :\n",
    "            data_dict[key]['poi_to_percent'] = data_dict[key]['from_poi_to_this_person'] \n",
    "            / float(data_dict[key]['to_messages'])\n",
    "    else:\n",
    "        data_dict[key]['poi_to_percent'] = 'NaN'\n",
    "\n",
    "for key in data_dict:\n",
    "    if (data_dict[key]['from_messages'] != 'NaN' and \n",
    "        data_dict[key]['from_messages'] != 0 and \n",
    "        data_dict[key]['from_this_person_to_poi'] != 'NaN' and \n",
    "        data_dict[key]['from_this_person_to_poi'] != 0) :\n",
    "            data_dict[key]['poi_from_percent'] = data_dict[key]['from_this_person_to_poi'] \n",
    "            / float(data_dict[key]['from_messages'])\n",
    "    else:\n",
    "        data_dict[key]['poi_from_percent'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list.pop()\n",
    "features_list.pop()\n",
    "features_list.append('poi_to_percent')\n",
    "features_list.append('poi_from_percent')\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = dict(data_dict)\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Try a varity of classifiers\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# split data into train and test sets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=19)\n",
    "\n",
    "# create a simple function to calculate list average\n",
    "def avg_list(l):\n",
    "    return sum(l) / float(len(l))\n",
    "\n",
    "print '============================='\n",
    "print 'Try a varity of classifiers'\n",
    "print '============================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes f1_score: 0.186666666667\n",
      "naive_bayes precision_score: 0.2\n",
      "naive_bayes recall_score: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenpinghsuan/Documents/Kaggle/virenv/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenpinghsuan/Documents/Kaggle/virenv/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# try naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_naive_bayes = GaussianNB()\n",
    "    clf_naive_bayes.fit(features_train, labels_train)\n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_naive_bayes = clf_naive_bayes.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_naive_bayes))\n",
    "    precisions.append(precision_score(labels_test, pred_naive_bayes))\n",
    "    recalls.append(recall_score(labels_test, pred_naive_bayes))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('naive_bayes', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('naive_bayes', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('naive_bayes', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors f1_score: 0.0666666666667\n",
      "KNeighbors precision_score: 0.1\n",
      "KNeighbors recall_score: 0.05\n"
     ]
    }
   ],
   "source": [
    "# try k-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_neigh = KNeighborsClassifier()\n",
    "    clf_neigh.fit(features_train, labels_train) \n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_neigh = clf_neigh.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_neigh))\n",
    "    precisions.append(precision_score(labels_test, pred_neigh))\n",
    "    recalls.append(recall_score(labels_test, pred_neigh))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('KNeighbors', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('KNeighbors', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('KNeighbors', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest f1_score: 0.381587301587\n",
      "random forest precision_score: 0.293571428571\n",
      "random forest recall_score: 0.65\n"
     ]
    }
   ],
   "source": [
    "# try random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_rf = RandomForestClassifier(max_depth=2, random_state=14, class_weight = 'balanced')\n",
    "    clf_rf.fit(features_train, labels_train) \n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_rf = clf_rf.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_rf))\n",
    "    precisions.append(precision_score(labels_test, pred_rf))\n",
    "    recalls.append(recall_score(labels_test, pred_rf))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('random forest', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('random forest', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('random forest', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm f1_score: 0.0\n",
      "svm precision_score: 0.0\n",
      "svm recall_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# try svm\n",
    "from sklearn import svm\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_svm = svm.SVC(class_weight = 'balanced')\n",
    "    clf_svm.fit(features_train, labels_train) \n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_svm = clf_svm.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_svm))\n",
    "    precisions.append(precision_score(labels_test, pred_svm))\n",
    "    recalls.append(recall_score(labels_test, pred_svm))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('svm', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('svm', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('svm', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost f1_score: 0.145238095238\n",
      "adaboost precision_score: 0.17\n",
      "adaboost recall_score: 0.15\n"
     ]
    }
   ],
   "source": [
    "# try adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_ada = AdaBoostClassifier(n_estimators=100)\n",
    "    clf_ada.fit(features_train, labels_train) \n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_ada = clf_ada.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_ada))\n",
    "    precisions.append(precision_score(labels_test, pred_ada))\n",
    "    recalls.append(recall_score(labels_test, pred_ada))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('adaboost', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('adaboost', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('adaboost', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree f1_score: 0.292142857143\n",
      "decision tree precision_score: 0.214166666667\n",
      "decision tree recall_score: 0.55\n"
     ]
    }
   ],
   "source": [
    "# try decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf_tree = tree.DecisionTreeClassifier(max_leaf_nodes=3, class_weight = 'balanced')\n",
    "    clf_tree.fit(features_train, labels_train) \n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_tree = clf_tree.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_tree))\n",
    "    precisions.append(precision_score(labels_test, pred_tree))\n",
    "    recalls.append(recall_score(labels_test, pred_tree))\n",
    "        \n",
    "print \"%s f1_score: %s\" % ('decision tree', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('decision tree', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('decision tree', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree pipe f1_score: 0.381587301587\n",
      "decision tree pipe precision_score: 0.293571428571\n",
      "decision tree pipe recall_score: 0.65\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# build a pipeline to do multi-stage operations\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "estimators = [('scaling', MinMaxScaler()), ('selectkbest', SelectKBest(k = 'all')), ('clf_rf',clf_rf)]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    pipe.fit(features_train,labels_train)\n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_pipe = pipe.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_pipe))\n",
    "    precisions.append(precision_score(labels_test, pred_pipe))\n",
    "    recalls.append(recall_score(labels_test, pred_pipe))\n",
    "    \n",
    "print \"%s f1_score: %s\" % ('decision tree pipe', avg_list(f1s)) \n",
    "print \"%s precision_score: %s\" %('decision tree pipe', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('decision tree pipe', avg_list(recalls))\n",
    "print ' ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "use tester to see how the current pipeline performs:\n",
      "=============================\n",
      "Pipeline(memory=None,\n",
      "     steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selectkbest', SelectKBest(k='all', score_func=<function f_classif at 0x10dded398>)), ('clf_rf', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "       ...stimators=10, n_jobs=1, oob_score=False, random_state=14,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.76407\tPrecision: 0.27467\tRecall: 0.46900\tF1: 0.34645\tF2: 0.41086\n",
      "\tTotal predictions: 15000\tTrue positives:  938\tFalse positives: 2477\tFalse negatives: 1062\tTrue negatives: 10523\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.htm\n",
    "\n",
    "# use tester to see how the current pipeline performs\n",
    "import tester\n",
    "print '============================='\n",
    "print 'use tester to see how the current pipeline performs:'\n",
    "print '============================='\n",
    "print tester.test_classifier(pipe, data_dict, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728.497822046\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "# use GridSearchCV to find out best parameters to selectkbest, random forest and pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'selectkbest__k': range(4,12), 'clf_rf__max_leaf_nodes': range(4,8),\n",
    "              'clf_rf__criterion': ['gini'], 'clf_rf__n_estimators': [200],               \n",
    "              'clf_rf__min_samples_split':range(2,5),'clf_rf__min_samples_leaf':range(4,10),              \n",
    "              'clf_rf__class_weight': ['balanced']}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid = parameters, scoring = 'f1', n_jobs = -1)\n",
    "gs.fit(features_train, labels_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "clf pipeline_refitted f1 score: 0.352857142857\n",
      "clf pipeline_refitted precision_score: 0.2875\n",
      "clf pipeline_refitted recall_score: 0.55\n"
     ]
    }
   ],
   "source": [
    "# use the parameters selected by GridSearchCV to refit random forest\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    features_train, features_test = np.array(features)[train_index], np.array(features)[test_index] \n",
    "    labels_train, labels_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "    \n",
    "    # fit the classifier using training data\n",
    "    clf.fit(features_train,labels_train)\n",
    "    \n",
    "    # test/predict the classifier over test data\n",
    "    pred_clf = clf.predict(features_test)\n",
    "    \n",
    "    # calculate precision and recall on test data & append these scores to the precision and recall lists above\n",
    "    f1s.append(f1_score(labels_test, pred_clf))\n",
    "    precisions.append(precision_score(labels_test, pred_clf))\n",
    "    recalls.append(recall_score(labels_test, pred_clf))\n",
    "\n",
    "\n",
    "print ' '\n",
    "print \"%s f1 score: %s\" %('clf pipeline_refitted', avg_list(f1s))\n",
    "print \"%s precision_score: %s\" %('clf pipeline_refitted', avg_list(precisions))\n",
    "print \"%s recall_score: %s\" % ('clf pipeline_refitted', avg_list(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "performance of refitted pipeline (using tester)\n",
      "=============================\n",
      "Pipeline(memory=None,\n",
      "     steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selectkbest', SelectKBest(k=11, score_func=<function f_classif at 0x10dded398>)), ('clf_rf', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "          ...timators=200, n_jobs=1, oob_score=False, random_state=14,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.77233\tPrecision: 0.30801\tRecall: 0.56750\tF1: 0.39930\tF2: 0.48567\n",
      "\tTotal predictions: 15000\tTrue positives: 1135\tFalse positives: 2550\tFalse negatives:  865\tTrue negatives: 10450\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print '============================='\n",
    "print 'performance of refitted pipeline (using tester)'\n",
    "print '============================='\n",
    "print tester.test_classifier(clf, data_dict, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "=============================\n",
      "features used in final pipeline/algorithm\n",
      "=============================\n",
      "['salary' 'total_payments' 'bonus' 'total_stock_value'\n",
      " 'exercised_stock_options' 'long_term_incentive' 'from_poi_to_this_person'\n",
      " 'from_this_person_to_poi' 'shared_receipt_with_poi' 'poi_to_percent'\n",
      " 'poi_from_percent']\n"
     ]
    }
   ],
   "source": [
    "kbest_step= clf.named_steps['selectkbest']\n",
    "idxs_selected= kbest_step.get_support()\n",
    "\n",
    "features_dataframe_new = np.array(features_list[1:])[idxs_selected]\n",
    "print ' '\n",
    "print '============================='\n",
    "print 'features used in final pipeline/algorithm'\n",
    "print '============================='\n",
    "print features_dataframe_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
